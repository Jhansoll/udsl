{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Naive Bayes Sentiment Analysis on Movie Reviews\n",
    "TA: Bokyung Son (*Computational Linguistics Lab, SNU*)\n",
    "\n",
    "### TASK: Classify each review phrase into negative(-1), neutral(0), or positive(1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes extends bayes' theorem to handle this case by assuming that each feature is independent.<br\\><br\\>\n",
    "$$P(y|x_{1}, \\dots, x_{n}) = \\frac{P(y)\\prod_{i=1}^{n}P(x_{i}|y)}{P(x_{1}, \\dots, x_{n})}$$\n",
    "\n",
    "We calculate the probabilities of each class $P(y)$ as well as the probabilities of each feature falling into each class $P(x_{i}|y)$. Then we return the class with the highest probability $P(y|x_{1}, \\dots, x_{n})$ as the \"correct\" classification.\n",
    "  \n",
    "As a BOW model, we use each word in a review as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset\n",
    "In this lab, we use the [Rotten tomatoes](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews) dataset. Check out the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with open('data/train.tsv', 'r') as file:\n",
    "    reviews = pd.DataFrame.from_csv(file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(reviews, score):\n",
    "    # Join texts of a particular tone\n",
    "    return ' '.join([r['Phrase'] for _, r in reviews.iterrows() if r['Sentiment'] in score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a mega-document for each tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative text sample: A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story . the gander \n",
      "\n",
      "Neutral text sample: A series of escapades demonstrating the adage that what is good for the goose A series A series of escapades demonstrating the adage that what is good for the goose of escapades demonstrating the adag\n",
      "\n",
      "Positive text sample: good for the goose good amuses This quiet , introspective and entertaining independent is worth seeking . This quiet , introspective and entertaining independent quiet , introspective and entertaining\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg_text = get_text(reviews, [0,1])\n",
    "ntr_text = get_text(reviews, [2])\n",
    "pos_text = get_text(reviews, [3,4])\n",
    "\n",
    "print(f'Negative text sample: {neg_text[:200]}', end='\\n\\n')\n",
    "print(f'Neutral text sample: {ntr_text[:200]}', end='\\n\\n')\n",
    "print(f'Positive text sample: {pos_text[:200]}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Collect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def count_words(text):\n",
    "    words = re.split(\"\\s+\", text)\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word counts for each score\n",
    "neg_word_counts = count_words(neg_text)\n",
    "ntr_word_counts = count_words(ntr_text)\n",
    "pos_word_counts = count_words(pos_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_y(reviews):\n",
    "    # Count each class\n",
    "    return reviews['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the counts of each tone\n",
    "class_counts = count_y(reviews)\n",
    "neg_review_count = class_counts[0] + class_counts[1]\n",
    "ntr_review_count = class_counts[2]\n",
    "pos_review_count = class_counts[3] + class_counts[4]\n",
    "\n",
    "# Class probabilities P(y)\n",
    "neg_prob = neg_review_count / len(reviews)\n",
    "ntr_prob = ntr_review_count / len(reviews)\n",
    "pos_prob = pos_review_count / len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Laplace (add-k) smoothing for max likelihood estimates. $\\lvert X \\rvert$ indicates vocabulary size.<br\\><br\\>\n",
    "$$P_{lap, k}(x_{i}|y) = \\frac{count(x_{i}, y) + k}{count(y) + k \\lvert X \\rvert}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, word_counts, class_prob, k):\n",
    "    \"\"\"\n",
    "    Computes probability (without the denominator) of a text(phrase) to fall into a certain class.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    text: the target text/phrase to classify.\n",
    "    word_counts: Counter for all words (features) in this class.\n",
    "    class_prob: P(this class)\n",
    "    k: Laplace smoothing factor (add-k)\n",
    "\n",
    "    \"\"\"\n",
    "    # Counter for the target text\n",
    "    word_counts_text = Counter(re.split(\"\\s+\", text))\n",
    "\n",
    "    prob = 1\n",
    "    for word in word_counts_text:\n",
    "        # Apply Laplace (add-k) smoothing\n",
    "        prob *= word_counts_text.get(word) * (word_counts.get(word, 0) + k) / (sum(word_counts.values()) + k * len(word_counts))\n",
    "    # Multiply by P(y)\n",
    "    return prob * class_prob\n",
    "\n",
    "\n",
    "def predict_class(text, word_counts_dict, class_prob_dict, k=1):\n",
    "    class_probs = {}\n",
    "    for cl, cl_prob in class_prob_dict.items():\n",
    "        class_probs[cl] = predict(text, word_counts_dict[cl], cl_prob, k)\n",
    "    return max(class_probs, key=(lambda key: class_probs[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample review: A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .\n",
      "Probability for being negative: 3.503012065587911e-85\n",
      "Probability for being neutral: 3.150976693599114e-84\n",
      "Probability for being positive: 1.9865028517931204e-86\n"
     ]
    }
   ],
   "source": [
    "# As you can see, we can now generate probabilities for which class a given review is part of.\n",
    "# The probabilities themselves aren't very useful -- we make our classification decision based on which value is greater.\n",
    "sample_review = reviews['Phrase'].iloc[0]\n",
    "print('Sample review: {0}'.format(sample_review))\n",
    "print('Probability for being negative: {0}'.format(predict(sample_review, neg_word_counts, neg_prob, 1)))\n",
    "print('Probability for being neutral: {0}'.format(predict(sample_review, ntr_word_counts, ntr_prob, 1)))\n",
    "print('Probability for being positive: {0}'.format(predict(sample_review, pos_word_counts, pos_prob, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "word_counts_dict = {}\n",
    "word_counts_dict[-1] = neg_word_counts\n",
    "word_counts_dict[0] = ntr_word_counts\n",
    "word_counts_dict[1] = pos_word_counts\n",
    "\n",
    "class_prob_dict = {}\n",
    "class_prob_dict[-1] = neg_prob\n",
    "class_prob_dict[0] = ntr_prob\n",
    "class_prob_dict[1] = pos_prob\n",
    "\n",
    "with open('data/test.tsv', 'r') as file:\n",
    "    test_reviews = pd.DataFrame.from_csv(file, sep='\\t')\n",
    "\n",
    "predictions = pd.DataFrame(columns=['Phrase', 'Sentiment'])\n",
    "for i, r in test_reviews[:500].iterrows():\n",
    "    predictions.loc[i] = [r['Phrase'], predict_class(r['Phrase'], word_counts_dict, class_prob_dict)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('output.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Generate counts from text\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_features = vectorizer.fit_transform(reviews['Phrase'])\n",
    "test_features = vectorizer.transform(test_reviews['Phrase'])\n",
    "\n",
    "# Train a NB model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_features, reviews['Sentiment'])\n",
    "\n",
    "# Predict for test data\n",
    "predictions = nb.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
